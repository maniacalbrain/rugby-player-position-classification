{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Rugby Player Position Classification\n",
    "\n",
    "The aim of this notebook is to see if it is possible to classify rugby players by position using data taken from the <a href=\"http://www.rugbyworldcup.com/\" target=\"_blank\">Rugby World Cup</a> website. <a href=\"http://www.anquantarbuile.com/static/images/plots/RWC2015semisheightweight.png\" target=\"_blank\">This plot</a> shows the squad members of the RWC semi-finalists plotted by country and position. The second plot show that some positions should be easy to predict based on height and weight, such as Prop, Lock and Hooker while Fly Half, Full Back and Wing would be a lot harder. I want to see if the addition of data on points and tries scored will help.\n",
    "\n",
    "The data below is taken from the bigger Rugby playing nations and was pulled down from the RWC website the day after the Final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "argentina = pd.read_csv('argentina.csv')\n",
    "australia = pd.read_csv('australia.csv')\n",
    "england = pd.read_csv('england.csv')\n",
    "france = pd.read_csv('france.csv')\n",
    "georgia = pd.read_csv('georgia.csv')   \n",
    "ireland = pd.read_csv('ireland.csv')\n",
    "italy = pd.read_csv('italy.csv')  \n",
    "new_zealand = pd.read_csv('new-zealand.csv')\n",
    "scotland = pd.read_csv('scotland.csv')\n",
    "south_africa = pd.read_csv('south-africa.csv')\n",
    "wales = pd.read_csv('wales.csv')\n",
    "\n",
    "frames = [argentina, australia, england, france, ireland, italy, new_zealand,\n",
    "          scotland, south_africa, wales]\n",
    "combined = pd.concat(frames).reset_index(drop = True) #create single dataframe containing all players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maniacalbrain\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Debut</th>\n",
       "      <th>Height</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Name</th>\n",
       "      <th>Points_Scored</th>\n",
       "      <th>Position</th>\n",
       "      <th>Red_Cards</th>\n",
       "      <th>Tries_Scored</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Yellow_Cards</th>\n",
       "      <th>﻿Name</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>17 May 2014</td>\n",
       "      <td>198</td>\n",
       "      <td>20</td>\n",
       "      <td>Matias Alemanno</td>\n",
       "      <td>10</td>\n",
       "      <td>Lock</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221.76</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>04 Dec 2004</td>\n",
       "      <td>186</td>\n",
       "      <td>65</td>\n",
       "      <td>Marcos Ayerza</td>\n",
       "      <td>5</td>\n",
       "      <td>Prop</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210.18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>23 Apr 2005</td>\n",
       "      <td>182</td>\n",
       "      <td>46</td>\n",
       "      <td>Agustín Creevy</td>\n",
       "      <td>10</td>\n",
       "      <td>Hooker</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.92</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>08 Nov 2008</td>\n",
       "      <td>190</td>\n",
       "      <td>20</td>\n",
       "      <td>Juan Pablo Orlandi</td>\n",
       "      <td>5</td>\n",
       "      <td>Prop</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>226.10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>28 Apr 2004</td>\n",
       "      <td>191</td>\n",
       "      <td>71</td>\n",
       "      <td>Juan Martín Fernandez Lobbe</td>\n",
       "      <td>25</td>\n",
       "      <td>Back Row</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age        Debut  Height  Matches                         Name  \\\n",
       "0   23  17 May 2014     198       20              Matias Alemanno   \n",
       "1   32  04 Dec 2004     186       65                Marcos Ayerza   \n",
       "2   30  23 Apr 2005     182       46               Agustín Creevy   \n",
       "3   32  08 Nov 2008     190       20           Juan Pablo Orlandi   \n",
       "4   33  28 Apr 2004     191       71  Juan Martín Fernandez Lobbe   \n",
       "\n",
       "   Points_Scored  Position  Red_Cards  Tries_Scored  Weight  Yellow_Cards  \\\n",
       "0             10      Lock          0             2     112             0   \n",
       "1              5      Prop          0             1     113             1   \n",
       "2             10    Hooker          0             2     106             0   \n",
       "3              5      Prop          0             1     119             0   \n",
       "4             25  Back Row          0             5     106             2   \n",
       "\n",
       "  ﻿Name    Mass  Target  \n",
       "0   NaN  221.76       5  \n",
       "1   NaN  210.18       6  \n",
       "2   NaN  192.92       4  \n",
       "3   NaN  226.10       6  \n",
       "4   NaN  202.46       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The Italian names seem to be causing the second Name column to appear, I didn't handle this when pulling down the data. \n",
    "\n",
    "#Clean Height and Weight columns, calculate Mass of players\n",
    "combined['Height'] = combined['Height'].map(lambda x: x.strip('cm')).astype(int)\n",
    "combined['Weight'] = combined['Weight'].map(lambda x: x.strip('kg')).astype(int)\n",
    "combined[\"Mass\"] = (combined[\"Height\"]/100) * combined[\"Weight\"]\n",
    "\n",
    "\n",
    "#Assign each position a numeric target to be predicted ie 0 = Back Row\n",
    "combined[\"Target\"] = 0\n",
    "for i, position in enumerate(np.unique(combined[\"Position\"])):\n",
    "    combined[\"Target\"][combined[\"Position\"] == position] = i\n",
    "\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Back Row'), (1, 'Centre'), (2, 'Fly Half'), (3, 'Full Back'), (4, 'Hooker'), (5, 'Lock'), (6, 'Prop'), (7, 'Scrum Half'), (8, 'Wing')]\n"
     ]
    }
   ],
   "source": [
    "#Zip the target values to the position values. This can be used later when looking at confusion matrix data\n",
    "pos_to_tar = zip(np.unique(combined.Target), np.unique(combined.Position))\n",
    "print pos_to_tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now need to deceide what data is and isn't useful. Name, Age and Debut are dropped. A players position doesn't depend on how many games they have played so this will be dropped as well but first will be used to create some new columns. Two player could play in the same position but one could have scored twice as many points if they have played twice as many games. Therefore I create columns for average points per game and average tries per game and then drop the absolute points, tries and matches column. \n",
    "\n",
    "The remaining columns are then normalised and scaled\n",
    "\n",
    "An area I didn't look into was differences between countries. Two players could play in the same position but one could have scored twice as many points if he plays for New-Zealand and the other plays for England. Even their average scores would be different, New-Zealand players scoring more on average. Something to look at would be normalisng and scaling the values of each country seperatly before combining all the countries to make a single dataframe so that the highest scoring player of each country would have a simulare number even if one averaged half as many points as another.\n",
    "\n",
    "Two \"test rows\" are added containing the data of two retired players. At the end the model will be fitted with all the data and asked to predict the positions they played in based on their career data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points_Scored</th>\n",
       "      <th>Tries_Scored</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>184</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>165.60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>183</td>\n",
       "      <td>95</td>\n",
       "      <td>81</td>\n",
       "      <td>352</td>\n",
       "      <td>13</td>\n",
       "      <td>173.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>184</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167.44</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>178</td>\n",
       "      <td>93</td>\n",
       "      <td>133</td>\n",
       "      <td>245</td>\n",
       "      <td>46</td>\n",
       "      <td>165.54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>183</td>\n",
       "      <td>83</td>\n",
       "      <td>128</td>\n",
       "      <td>1083</td>\n",
       "      <td>16</td>\n",
       "      <td>151.89</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Height  Weight  Matches  Points_Scored  Tries_Scored    Mass  Target\n",
       "327     184      90        3              4             0  165.60       3\n",
       "328     183      95       81            352            13  173.85       1\n",
       "329     184      91        1              0             0  167.44       8\n",
       "330     178      93      133            245            46  165.54     NaN\n",
       "331     183      83      128           1083            16  151.89     NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a single dataframe containing the useful data.\n",
    "\n",
    "to_merge = [combined.Height, combined.Weight, combined.Matches, combined.Points_Scored, combined.Tries_Scored, combined.Mass, combined.Target]\n",
    "combined = pd.concat(to_merge, axis = 1)\n",
    "\n",
    "#Add two rows to be predicted afterwards\n",
    "test_rows = pd.DataFrame([[178, 93, 133, 245, 46, 165.54, np.nan],\n",
    "                        [183, 83, 128, 1083, 16, 151.89, np.nan]],\n",
    "                        columns = list(combined.columns))\n",
    "\n",
    "combined = combined.append(test_rows).reset_index(drop=True)\n",
    "\n",
    "combined.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points_Scored</th>\n",
       "      <th>Tries_Scored</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Target</th>\n",
       "      <th>Avg_Pts</th>\n",
       "      <th>Avg_Tries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198</td>\n",
       "      <td>112</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>221.76</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>113</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>210.18</td>\n",
       "      <td>6</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.015385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182</td>\n",
       "      <td>106</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>192.92</td>\n",
       "      <td>4</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190</td>\n",
       "      <td>119</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>226.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191</td>\n",
       "      <td>106</td>\n",
       "      <td>71</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>202.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.070423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Height  Weight  Matches  Points_Scored  Tries_Scored    Mass  Target  \\\n",
       "0     198     112       20             10             2  221.76       5   \n",
       "1     186     113       65              5             1  210.18       6   \n",
       "2     182     106       46             10             2  192.92       4   \n",
       "3     190     119       20              5             1  226.10       6   \n",
       "4     191     106       71             25             5  202.46       0   \n",
       "\n",
       "    Avg_Pts  Avg_Tries  \n",
       "0  0.500000   0.100000  \n",
       "1  0.076923   0.015385  \n",
       "2  0.217391   0.043478  \n",
       "3  0.250000   0.050000  \n",
       "4  0.352113   0.070423  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate Average points per game and Average tries per game\n",
    "combined[\"Avg_Pts\"] = combined.Points_Scored.astype(\"float\")/combined.Matches.astype(\"float\")\n",
    "combined[\"Avg_Tries\"] = combined.Tries_Scored.astype(\"float\")/combined.Matches.astype(\"float\")\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Some players have played no games and will end up with null values after the above division. Set these values to 0. \n",
    "\n",
    "combined.Avg_Pts = combined.Avg_Pts.fillna(0)\n",
    "combined.Avg_Tries = combined.Avg_Tries.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Target</th>\n",
       "      <th>Avg_Pts</th>\n",
       "      <th>Avg_Tries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198</td>\n",
       "      <td>112</td>\n",
       "      <td>221.76</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>113</td>\n",
       "      <td>210.18</td>\n",
       "      <td>6</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.015385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182</td>\n",
       "      <td>106</td>\n",
       "      <td>192.92</td>\n",
       "      <td>4</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190</td>\n",
       "      <td>119</td>\n",
       "      <td>226.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191</td>\n",
       "      <td>106</td>\n",
       "      <td>202.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.070423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Height  Weight    Mass  Target   Avg_Pts  Avg_Tries\n",
       "0     198     112  221.76       5  0.500000   0.100000\n",
       "1     186     113  210.18       6  0.076923   0.015385\n",
       "2     182     106  192.92       4  0.217391   0.043478\n",
       "3     190     119  226.10       6  0.250000   0.050000\n",
       "4     191     106  202.46       0  0.352113   0.070423"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop mathes, points and tries scored\n",
    "\n",
    "combined=combined.drop([\"Matches\", \"Points_Scored\", \"Tries_Scored\"], axis = 1)\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Target</th>\n",
       "      <th>Avg_Pts</th>\n",
       "      <th>Avg_Tries</th>\n",
       "      <th>Height_norm</th>\n",
       "      <th>Height_scaled</th>\n",
       "      <th>Weight_norm</th>\n",
       "      <th>Weight_scaled</th>\n",
       "      <th>Mass_norm</th>\n",
       "      <th>Mass_scaled</th>\n",
       "      <th>Avg_Pts_norm</th>\n",
       "      <th>Avg_Pts_scaled</th>\n",
       "      <th>Avg_Tries_norm</th>\n",
       "      <th>Avg_Tries_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198</td>\n",
       "      <td>112</td>\n",
       "      <td>221.76</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.264179</td>\n",
       "      <td>0.149038</td>\n",
       "      <td>0.105502</td>\n",
       "      <td>0.289655</td>\n",
       "      <td>0.156322</td>\n",
       "      <td>0.367093</td>\n",
       "      <td>-0.043478</td>\n",
       "      <td>0.035044</td>\n",
       "      <td>-0.027454</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>113</td>\n",
       "      <td>210.18</td>\n",
       "      <td>6</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>-0.028504</td>\n",
       "      <td>0.091346</td>\n",
       "      <td>0.118835</td>\n",
       "      <td>0.296552</td>\n",
       "      <td>0.087700</td>\n",
       "      <td>0.326553</td>\n",
       "      <td>-0.073130</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>-0.112070</td>\n",
       "      <td>0.015385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182</td>\n",
       "      <td>106</td>\n",
       "      <td>192.92</td>\n",
       "      <td>4</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>-0.126065</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>0.025502</td>\n",
       "      <td>0.248276</td>\n",
       "      <td>-0.014581</td>\n",
       "      <td>0.266130</td>\n",
       "      <td>-0.063285</td>\n",
       "      <td>0.015236</td>\n",
       "      <td>-0.083976</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190</td>\n",
       "      <td>119</td>\n",
       "      <td>226.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.069057</td>\n",
       "      <td>0.110577</td>\n",
       "      <td>0.198835</td>\n",
       "      <td>0.337931</td>\n",
       "      <td>0.182041</td>\n",
       "      <td>0.382286</td>\n",
       "      <td>-0.061000</td>\n",
       "      <td>0.017522</td>\n",
       "      <td>-0.077454</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191</td>\n",
       "      <td>106</td>\n",
       "      <td>202.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.093447</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.025502</td>\n",
       "      <td>0.248276</td>\n",
       "      <td>0.041952</td>\n",
       "      <td>0.299527</td>\n",
       "      <td>-0.053843</td>\n",
       "      <td>0.024679</td>\n",
       "      <td>-0.057032</td>\n",
       "      <td>0.070423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Height  Weight    Mass  Target   Avg_Pts  Avg_Tries  Height_norm  \\\n",
       "0     198     112  221.76       5  0.500000   0.100000     0.264179   \n",
       "1     186     113  210.18       6  0.076923   0.015385    -0.028504   \n",
       "2     182     106  192.92       4  0.217391   0.043478    -0.126065   \n",
       "3     190     119  226.10       6  0.250000   0.050000     0.069057   \n",
       "4     191     106  202.46       0  0.352113   0.070423     0.093447   \n",
       "\n",
       "   Height_scaled  Weight_norm  Weight_scaled  Mass_norm  Mass_scaled  \\\n",
       "0       0.149038     0.105502       0.289655   0.156322     0.367093   \n",
       "1       0.091346     0.118835       0.296552   0.087700     0.326553   \n",
       "2       0.072115     0.025502       0.248276  -0.014581     0.266130   \n",
       "3       0.110577     0.198835       0.337931   0.182041     0.382286   \n",
       "4       0.115385     0.025502       0.248276   0.041952     0.299527   \n",
       "\n",
       "   Avg_Pts_norm  Avg_Pts_scaled  Avg_Tries_norm  Avg_Tries_scaled  \n",
       "0     -0.043478        0.035044       -0.027454          0.100000  \n",
       "1     -0.073130        0.005391       -0.112070          0.015385  \n",
       "2     -0.063285        0.015236       -0.083976          0.043478  \n",
       "3     -0.061000        0.017522       -0.077454          0.050000  \n",
       "4     -0.053843        0.024679       -0.057032          0.070423  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create normalized and scaled transformations of the remaining values.\n",
    "to_transform = [\"Height\", \"Weight\", \"Mass\", \"Avg_Pts\", \"Avg_Tries\"]\n",
    "for factor in to_transform:\n",
    "    factor_norm = factor + \"_norm\"\n",
    "    factor_scale = factor + \"_scaled\"\n",
    "    combined[factor_norm] = (combined[factor] - combined[factor].mean()) / (combined[factor].max() - combined[factor].min())\n",
    "    combined[factor_scale] = (combined[factor] - combined[factor].min()) / combined[factor].max()\n",
    "    \n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a dataframe to hold the two test_rows and remove them from the combined dataframe\n",
    "\n",
    "test_rows = combined[combined.Target.isnull()]\n",
    "combined = combined[combined.Target.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Avg_Pts</th>\n",
       "      <th>Avg_Tries</th>\n",
       "      <th>Height_norm</th>\n",
       "      <th>Height_scaled</th>\n",
       "      <th>Weight_norm</th>\n",
       "      <th>Weight_scaled</th>\n",
       "      <th>Mass_norm</th>\n",
       "      <th>Mass_scaled</th>\n",
       "      <th>Avg_Pts_norm</th>\n",
       "      <th>Avg_Pts_scaled</th>\n",
       "      <th>Avg_Tries_norm</th>\n",
       "      <th>Avg_Tries_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198</td>\n",
       "      <td>112</td>\n",
       "      <td>221.76</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.264179</td>\n",
       "      <td>0.149038</td>\n",
       "      <td>0.105502</td>\n",
       "      <td>0.289655</td>\n",
       "      <td>0.156322</td>\n",
       "      <td>0.367093</td>\n",
       "      <td>-0.043478</td>\n",
       "      <td>0.035044</td>\n",
       "      <td>-0.027454</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>113</td>\n",
       "      <td>210.18</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>-0.028504</td>\n",
       "      <td>0.091346</td>\n",
       "      <td>0.118835</td>\n",
       "      <td>0.296552</td>\n",
       "      <td>0.087700</td>\n",
       "      <td>0.326553</td>\n",
       "      <td>-0.073130</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>-0.112070</td>\n",
       "      <td>0.015385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182</td>\n",
       "      <td>106</td>\n",
       "      <td>192.92</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>-0.126065</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>0.025502</td>\n",
       "      <td>0.248276</td>\n",
       "      <td>-0.014581</td>\n",
       "      <td>0.266130</td>\n",
       "      <td>-0.063285</td>\n",
       "      <td>0.015236</td>\n",
       "      <td>-0.083976</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190</td>\n",
       "      <td>119</td>\n",
       "      <td>226.10</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.069057</td>\n",
       "      <td>0.110577</td>\n",
       "      <td>0.198835</td>\n",
       "      <td>0.337931</td>\n",
       "      <td>0.182041</td>\n",
       "      <td>0.382286</td>\n",
       "      <td>-0.061000</td>\n",
       "      <td>0.017522</td>\n",
       "      <td>-0.077454</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191</td>\n",
       "      <td>106</td>\n",
       "      <td>202.46</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.093447</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.025502</td>\n",
       "      <td>0.248276</td>\n",
       "      <td>0.041952</td>\n",
       "      <td>0.299527</td>\n",
       "      <td>-0.053843</td>\n",
       "      <td>0.024679</td>\n",
       "      <td>-0.057032</td>\n",
       "      <td>0.070423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Height  Weight    Mass   Avg_Pts  Avg_Tries  Height_norm  Height_scaled  \\\n",
       "0     198     112  221.76  0.500000   0.100000     0.264179       0.149038   \n",
       "1     186     113  210.18  0.076923   0.015385    -0.028504       0.091346   \n",
       "2     182     106  192.92  0.217391   0.043478    -0.126065       0.072115   \n",
       "3     190     119  226.10  0.250000   0.050000     0.069057       0.110577   \n",
       "4     191     106  202.46  0.352113   0.070423     0.093447       0.115385   \n",
       "\n",
       "   Weight_norm  Weight_scaled  Mass_norm  Mass_scaled  Avg_Pts_norm  \\\n",
       "0     0.105502       0.289655   0.156322     0.367093     -0.043478   \n",
       "1     0.118835       0.296552   0.087700     0.326553     -0.073130   \n",
       "2     0.025502       0.248276  -0.014581     0.266130     -0.063285   \n",
       "3     0.198835       0.337931   0.182041     0.382286     -0.061000   \n",
       "4     0.025502       0.248276   0.041952     0.299527     -0.053843   \n",
       "\n",
       "   Avg_Pts_scaled  Avg_Tries_norm  Avg_Tries_scaled  \n",
       "0        0.035044       -0.027454          0.100000  \n",
       "1        0.005391       -0.112070          0.015385  \n",
       "2        0.015236       -0.083976          0.043478  \n",
       "3        0.017522       -0.077454          0.050000  \n",
       "4        0.024679       -0.057032          0.070423  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract the target values and drop them from combined and test_row dataframes. These are now ready to be used in a classifier\n",
    "\n",
    "target = combined.Target\n",
    "combined = combined.drop([\"Target\"], axis = 1)\n",
    "test_rows = test_rows.drop([\"Target\"], axis = 1)\n",
    "\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Fitting a Random Forest Classification\n",
    "\n",
    "We now have the values we are going to use for classification. However we have both height, weight and mass, the latter a value found by combining the first two. So the information held by this value is also held in the first two. On some runs of the below classifiers I found height and weight to always be a small bit more important then mass so in the below I will drop mass.\n",
    "\n",
    "I will create three data frames from the original, one for the starting or simple values, one for the normalized values and one for the scaled values. I will then convert these and the target values to an np.array as required by the classifiers.\n",
    "\n",
    "I used both logistic regressors and a gradient boosting regressor but found better results with the random forest and will used that below. It may be worth trying an Extra Trees Classifier, AdaBoosting or Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create 3 dataframes with the relevent data\n",
    "simple_values = [combined['Height'], combined['Weight'],  combined['Avg_Pts'], combined['Avg_Tries']]\n",
    "norm_values = [combined['Height_norm'], combined['Weight_norm'],  combined['Avg_Pts_norm'], combined['Avg_Tries_norm']]\n",
    "scale_values = [combined['Height_scaled'], combined['Weight_scaled'],  combined['Avg_Pts_scaled'], combined['Avg_Tries_scaled']]\n",
    "\n",
    "simple_df = pd.concat(simple_values, axis=1)\n",
    "norm_df = pd.concat(norm_values, axis = 1)\n",
    "scale_df = pd.concat(scale_values, axis = 1)\n",
    "\n",
    "#convert each dataframe to an np.array\n",
    "simple_X = simple_df.values\n",
    "norm_X = norm_df.values\n",
    "scale_X = scale_df.values\n",
    "\n",
    "#convert target to np.array\n",
    "Y = target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I create a random forest classifier for each of the 3 X values and carry out cross validation as there is so little data. It is often best to set n_estimators to a high value on random forests so I start at 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "0.648639459077\n",
      "0.0542635555778\n",
      "\n",
      "0.632830001236\n",
      "0.041490754897\n",
      "\n",
      "0.642165477851\n",
      "0.0424758937055\n"
     ]
    }
   ],
   "source": [
    "#Important imports\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "% pylab inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "simple_rfc = RandomForestClassifier(n_estimators=2000)\n",
    "scores = cross_val_score(simple_rfc, simple_X, Y, cv = 5)\n",
    "print scores.mean()\n",
    "print scores.std()\n",
    "\n",
    "print \"\"\n",
    "\n",
    "norm_rfc = RandomForestClassifier(n_estimators=2000)\n",
    "scores = cross_val_score(norm_rfc, norm_X, Y, cv = 5)\n",
    "print scores.mean()\n",
    "print scores.std()\n",
    "\n",
    "print \"\"\n",
    "\n",
    "scale_rfc = RandomForestClassifier(n_estimators=2000)\n",
    "scores = cross_val_score(scale_rfc, scale_X, Y, cv = 5)\n",
    "print scores.mean()\n",
    "print scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers are very similar, averaging at 63-64% accuracy, which over 9 classes isn't that bad. Random guessing would give us a baseline of 11%! The highest value returned above is for the simple model but over repeated runnings the scaled model often performs better and returns a lower standered deviation. This is the model I'm going to use below but this show it is important to carry out multiple runs to find which model consistantly returns the best values. It is also worth weighing up what you want from a model, high accuracy or low standard deviation. \n",
    "\n",
    "Below I will fit an RFC with all the avalible data to calculate the feature importances. As I am using scale_rfc from above this has 2000 estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Weight_norm', 0.31216546498106323),\n",
       " ('Height_norm', 0.31096799076471909),\n",
       " ('Avg_Pts_norm', 0.20838441127001803),\n",
       " ('Avg_Tries_norm', 0.1684821329842007)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_rfc.fit(scale_X,Y)\n",
    "sorted(zip(scale_df.columns, scale_rfc.feature_importances_),key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight and Height are very important for predicting a players position, making up 62% of the model. Now I'll use a confusion matrix to see which positions the model is predicting well and which it is not. To do this I will need to predict data for a number of rows. I will need to fit an rfc with a portion of the dataframe and then get it to predict the remaining portion. The confusion matrix will then compare these predicted values to the real values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a53a320>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD7CAYAAABZjGkWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17579e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(scale_X, Y)\n",
    "\n",
    "scale_rfc.fit(x_train, y_train)\n",
    "scale_pred = scale_rfc.predict(x_test)\n",
    "scale_rfc_cm = confusion_matrix(y_test, scale_pred)\n",
    "plt.imshow(scale_rfc_cm, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Back Row'), (1, 'Centre'), (2, 'Fly Half'), (3, 'Full Back'), (4, 'Hooker'), (5, 'Lock'), (6, 'Prop'), (7, 'Scrum Half'), (8, 'Wing')]\n"
     ]
    }
   ],
   "source": [
    "print pos_to_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  2,  0,  0,  0,  1,  1,  0,  1],\n",
       "       [ 1,  1,  1,  1,  0,  1,  0,  0,  2],\n",
       "       [ 0,  0,  4,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  4,  1,  0,  0,  0,  0,  1,  1],\n",
       "       [ 2,  1,  0,  0,  3,  0,  4,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 10,  0,  0,  0],\n",
       "       [ 3,  0,  0,  0,  1,  0,  7,  0,  0],\n",
       "       [ 0,  2,  1,  0,  0,  0,  0,  4,  0],\n",
       "       [ 0,  2,  0,  0,  0,  1,  0,  0,  8]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_rfc_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the plotted and numeric version of the confusion matrix are shown above with the positions mapped to their targets. The model is getting every single Lock correct (5th row, with 0th row at the top) and is getting every single Full Back wrong, thinking that they are all Centres(3rd row). Centre and Hooker are also poor.\n",
    "\n",
    "Below is a classification report. To help read it used row 6 (Prop) above and remember:\n",
    "True Positive: Times model predicted correctly (predicted Prop, was Prop = 7)\n",
    "\n",
    "False Positive: Times model predicted a position when it wasn't that position. Sum of incorrect values in a column. (Predicted Prop, wasn't: 1 back row and 4 hookers predicted as prop = 5)\n",
    "\n",
    "False Negative: Times model predicted a specific position to be other then it was. Sum of incorrect values in a row (Was a Prop but predicted otherwise: 3 props predicted as Back Row, 1 as Hooker = 4)\n",
    "\n",
    "Precision = tp/(tp+fp) = 7/(7+5) = 0.583 - If the model guesses Prop what percentage of the time is it right\n",
    "Recall = tp/(tp+fn) = 7/(7+4) = 0.636 - What percentage of Props did I guess correctly\n",
    "\n",
    "f1-score = 2 x (precision x recall)/ (precision + recall) = 2 x (0.583 x 0.636) / (0.583 + 0.636) = 0.608\n",
    "This can be considered a weighted average of the precision and recall scores. Higher the better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Back Row       0.65      0.69      0.67        16\n",
      "     Centre       0.08      0.14      0.11         7\n",
      "   Fly Half       0.57      1.00      0.73         4\n",
      "  Full Back       0.00      0.00      0.00         7\n",
      "     Hooker       0.75      0.30      0.43        10\n",
      "       Lock       0.77      1.00      0.87        10\n",
      "       Prop       0.58      0.64      0.61        11\n",
      " Scrum Half       0.80      0.57      0.67         7\n",
      "       Wing       0.67      0.73      0.70        11\n",
      "\n",
      "avg / total       0.58      0.58      0.56        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "positions = [\"Back Row\", \"Centre\", \"Fly Half\", \"Full Back\", \"Hooker\", \"Lock\", \"Prop\", \"Scrum Half\", \"Wing\"]\n",
    "print classification_report(y_test, scale_pred, target_names=positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centre, Full-Back and Hooker are pretty rubbish. We have a very big tendency to predict things as centre when they aren't where as we only do this a few times with scrum-halfs (Precision). The model got all the locks and Fly-Halfs right but didn't get a single ful back. Surprise, surprise, looking at our confusion matrix above we see it thought most of them were centres.\n",
    "\n",
    "Below I do a very limited GridSearch to find some paramaters to imporve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV] n_estimators=1000, criterion=gini, max_depth=1 ..................\n",
      "[CV]  n_estimators=1000, criterion=gini, max_depth=1, score=0.482353 -   2.1s\n",
      "[CV] n_estimators=1000, criterion=gini, max_depth=1 ..................\n",
      "[CV]  n_estimators=1000, criterion=gini, max_depth=1, score=0.451220 -   2.1s\n",
      "[CV] n_estimators=1000, criterion=gini, max_depth=1 ..................\n",
      "[CV]  n_estimators=1000, criterion=gini, max_depth=1, score=0.487500 -   2.1s\n",
      "[CV] n_estimators=2000, criterion=gini, max_depth=1 ..................\n",
      "[CV]  n_estimators=2000, criterion=gini, max_depth=1, score=0.494118 -   4.7s\n",
      "[CV] n_estimators=2000, criterion=gini, max_depth=1 ..................\n",
      "[CV]  n_estimators=2000, criterion=gini, max_depth=1, score=0.451220 -   4.4s\n",
      "[CV] n_estimators=2000, criterion=gini, max_depth=1 ..................\n",
      "[CV]  n_estimators=2000, criterion=gini, max_depth=1, score=0.500000 -   4.3s\n",
      "[CV] n_estimators=3000, criterion=gini, max_depth=1 ..................\n",
      "[CV]  n_estimators=3000, criterion=gini, max_depth=1, score=0.482353 -   6.6s\n",
      "[CV] n_estimators=3000, criterion=gini, max_depth=1 ..................\n",
      "[CV]  n_estimators=3000, criterion=gini, max_depth=1, score=0.426829 -   6.5s\n",
      "[CV] n_estimators=3000, criterion=gini, max_depth=1 ..................\n",
      "[CV]  n_estimators=3000, criterion=gini, max_depth=1, score=0.487500 -   6.5s\n",
      "[CV] n_estimators=1000, criterion=gini, max_depth=2 ..................\n",
      "[CV]  n_estimators=1000, criterion=gini, max_depth=2, score=0.541176 -   2.1s\n",
      "[CV] n_estimators=1000, criterion=gini, max_depth=2 ..................\n",
      "[CV]  n_estimators=1000, criterion=gini, max_depth=2, score=0.585366 -   2.2s\n",
      "[CV] n_estimators=1000, criterion=gini, max_depth=2 ..................\n",
      "[CV]  n_estimators=1000, criterion=gini, max_depth=2, score=0.700000 -   2.2s\n",
      "[CV] n_estimators=2000, criterion=gini, max_depth=2 ..................\n",
      "[CV]  n_estimators=2000, criterion=gini, max_depth=2, score=0.552941 -   4.4s\n",
      "[CV] n_estimators=2000, criterion=gini, max_depth=2 ..................\n",
      "[CV]  n_estimators=2000, criterion=gini, max_depth=2, score=0.573171 -   4.4s\n",
      "[CV] n_estimators=2000, criterion=gini, max_depth=2 ..................\n",
      "[CV]  n_estimators=2000, criterion=gini, max_depth=2, score=0.637500 -   4.4s\n",
      "[CV] n_estimators=3000, criterion=gini, max_depth=2 ..................\n",
      "[CV]  n_estimators=3000, criterion=gini, max_depth=2, score=0.552941 -   6.8s\n",
      "[CV] n_estimators=3000, criterion=gini, max_depth=2 ..................\n",
      "[CV]  n_estimators=3000, criterion=gini, max_depth=2, score=0.560976 -   6.6s\n",
      "[CV] n_estimators=3000, criterion=gini, max_depth=2 ..................\n",
      "[CV]  n_estimators=3000, criterion=gini, max_depth=2, score=0.625000 -   6.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done  18 jobs       | elapsed:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] n_estimators=1000, criterion=gini, max_depth=3 ..................\n",
      "[CV]  n_estimators=1000, criterion=gini, max_depth=3, score=0.576471 -   2.3s\n",
      "[CV] n_estimators=1000, criterion=gini, max_depth=3 ..................\n",
      "[CV]  n_estimators=1000, criterion=gini, max_depth=3, score=0.621951 -   2.2s\n",
      "[CV] n_estimators=1000, criterion=gini, max_depth=3 ..................\n",
      "[CV]  n_estimators=1000, criterion=gini, max_depth=3, score=0.725000 -   2.2s\n",
      "[CV] n_estimators=2000, criterion=gini, max_depth=3 ..................\n",
      "[CV]  n_estimators=2000, criterion=gini, max_depth=3, score=0.576471 -   4.5s\n",
      "[CV] n_estimators=2000, criterion=gini, max_depth=3 ..................\n",
      "[CV]  n_estimators=2000, criterion=gini, max_depth=3, score=0.609756 -   4.5s\n",
      "[CV] n_estimators=2000, criterion=gini, max_depth=3 ..................\n",
      "[CV]  n_estimators=2000, criterion=gini, max_depth=3, score=0.750000 -   4.5s\n",
      "[CV] n_estimators=3000, criterion=gini, max_depth=3 ..................\n",
      "[CV]  n_estimators=3000, criterion=gini, max_depth=3, score=0.564706 -   6.7s\n",
      "[CV] n_estimators=3000, criterion=gini, max_depth=3 ..................\n",
      "[CV]  n_estimators=3000, criterion=gini, max_depth=3, score=0.621951 -   6.8s\n",
      "[CV] n_estimators=3000, criterion=gini, max_depth=3 ..................\n",
      "[CV]  n_estimators=3000, criterion=gini, max_depth=3, score=0.737500 -   6.9s\n",
      "[CV] n_estimators=1000, criterion=gini, max_depth=4 ..................\n",
      "[CV]  n_estimators=1000, criterion=gini, max_depth=4, score=0.635294 -   2.2s\n",
      "[CV] n_estimators=1000, criterion=gini, max_depth=4 ..................\n",
      "[CV]  n_estimators=1000, criterion=gini, max_depth=4, score=0.695122 -   2.2s\n",
      "[CV] n_estimators=1000, criterion=gini, max_depth=4 ..................\n",
      "[CV]  n_estimators=1000, criterion=gini, max_depth=4, score=0.712500 -   2.2s\n",
      "[CV] n_estimators=2000, criterion=gini, max_depth=4 ..................\n",
      "[CV]  n_estimators=2000, criterion=gini, max_depth=4, score=0.635294 -   4.6s\n",
      "[CV] n_estimators=2000, criterion=gini, max_depth=4 ..................\n",
      "[CV]  n_estimators=2000, criterion=gini, max_depth=4, score=0.695122 -   4.6s\n",
      "[CV] n_estimators=2000, criterion=gini, max_depth=4 ..................\n",
      "[CV]  n_estimators=2000, criterion=gini, max_depth=4, score=0.725000 -   4.6s\n",
      "[CV] n_estimators=3000, criterion=gini, max_depth=4 ..................\n",
      "[CV]  n_estimators=3000, criterion=gini, max_depth=4, score=0.611765 -   6.9s\n",
      "[CV] n_estimators=3000, criterion=gini, max_depth=4 ..................\n",
      "[CV]  n_estimators=3000, criterion=gini, max_depth=4, score=0.682927 -   6.9s\n",
      "[CV] n_estimators=3000, criterion=gini, max_depth=4 ..................\n",
      "[CV]  n_estimators=3000, criterion=gini, max_depth=4, score=0.700000 -   7.1s\n",
      "[CV] n_estimators=1000, criterion=gini, max_depth=None ...............\n",
      "[CV]  n_estimators=1000, criterion=gini, max_depth=None, score=0.635294 -   2.9s\n",
      "[CV] n_estimators=1000, criterion=gini, max_depth=None ...............\n",
      "[CV]  n_estimators=1000, criterion=gini, max_depth=None, score=0.646341 -   2.4s\n",
      "[CV] n_estimators=1000, criterion=gini, max_depth=None ...............\n",
      "[CV]  n_estimators=1000, criterion=gini, max_depth=None, score=0.675000 -   2.4s\n",
      "[CV] n_estimators=2000, criterion=gini, max_depth=None ...............\n",
      "[CV]  n_estimators=2000, criterion=gini, max_depth=None, score=0.635294 -   4.9s\n",
      "[CV] n_estimators=2000, criterion=gini, max_depth=None ...............\n",
      "[CV]  n_estimators=2000, criterion=gini, max_depth=None, score=0.634146 -   4.9s\n",
      "[CV] n_estimators=2000, criterion=gini, max_depth=None ...............\n",
      "[CV]  n_estimators=2000, criterion=gini, max_depth=None, score=0.662500 -   4.9s\n",
      "[CV] n_estimators=3000, criterion=gini, max_depth=None ...............\n",
      "[CV]  n_estimators=3000, criterion=gini, max_depth=None, score=0.635294 -   7.6s\n",
      "[CV] n_estimators=3000, criterion=gini, max_depth=None ...............\n",
      "[CV]  n_estimators=3000, criterion=gini, max_depth=None, score=0.634146 -   7.7s\n",
      "[CV] n_estimators=3000, criterion=gini, max_depth=None ...............\n",
      "[CV]  n_estimators=3000, criterion=gini, max_depth=None, score=0.675000 -   7.4s\n",
      "[CV] n_estimators=1000, criterion=entropy, max_depth=1 ...............\n",
      "[CV]  n_estimators=1000, criterion=entropy, max_depth=1, score=0.447059 -   2.3s\n",
      "[CV] n_estimators=1000, criterion=entropy, max_depth=1 ...............\n",
      "[CV]  n_estimators=1000, criterion=entropy, max_depth=1, score=0.426829 -   2.3s\n",
      "[CV] n_estimators=1000, criterion=entropy, max_depth=1 ...............\n",
      "[CV]  n_estimators=1000, criterion=entropy, max_depth=1, score=0.450000 -   2.3s\n",
      "[CV] n_estimators=2000, criterion=entropy, max_depth=1 ...............\n",
      "[CV]  n_estimators=2000, criterion=entropy, max_depth=1, score=0.447059 -   4.6s\n",
      "[CV] n_estimators=2000, criterion=entropy, max_depth=1 ...............\n",
      "[CV]  n_estimators=2000, criterion=entropy, max_depth=1, score=0.426829 -   4.6s\n",
      "[CV] n_estimators=2000, criterion=entropy, max_depth=1 ...............\n",
      "[CV]  n_estimators=2000, criterion=entropy, max_depth=1, score=0.450000 -   4.6s\n",
      "[CV] n_estimators=3000, criterion=entropy, max_depth=1 ...............\n",
      "[CV]  n_estimators=3000, criterion=entropy, max_depth=1, score=0.447059 -   7.0s\n",
      "[CV] n_estimators=3000, criterion=entropy, max_depth=1 ...............\n",
      "[CV]  n_estimators=3000, criterion=entropy, max_depth=1, score=0.414634 -   7.0s\n",
      "[CV] n_estimators=3000, criterion=entropy, max_depth=1 ...............\n",
      "[CV]  n_estimators=3000, criterion=entropy, max_depth=1, score=0.450000 -   7.0s\n",
      "[CV] n_estimators=1000, criterion=entropy, max_depth=2 ...............\n",
      "[CV]  n_estimators=1000, criterion=entropy, max_depth=2, score=0.517647 -   2.4s\n",
      "[CV] n_estimators=1000, criterion=entropy, max_depth=2 ...............\n",
      "[CV]  n_estimators=1000, criterion=entropy, max_depth=2, score=0.573171 -   2.4s\n",
      "[CV] n_estimators=1000, criterion=entropy, max_depth=2 ...............\n",
      "[CV]  n_estimators=1000, criterion=entropy, max_depth=2, score=0.612500 -   2.4s\n",
      "[CV] n_estimators=2000, criterion=entropy, max_depth=2 ...............\n",
      "[CV]  n_estimators=2000, criterion=entropy, max_depth=2, score=0.529412 -   4.9s\n",
      "[CV] n_estimators=2000, criterion=entropy, max_depth=2 ...............\n",
      "[CV]  n_estimators=2000, criterion=entropy, max_depth=2, score=0.560976 -   5.0s\n",
      "[CV] n_estimators=2000, criterion=entropy, max_depth=2 ...............\n",
      "[CV]  n_estimators=2000, criterion=entropy, max_depth=2, score=0.600000 -   4.9s\n",
      "[CV] n_estimators=3000, criterion=entropy, max_depth=2 ...............\n",
      "[CV]  n_estimators=3000, criterion=entropy, max_depth=2, score=0.541176 -   7.6s\n",
      "[CV] n_estimators=3000, criterion=entropy, max_depth=2 ...............\n",
      "[CV]  n_estimators=3000, criterion=entropy, max_depth=2, score=0.585366 -   7.5s\n",
      "[CV] n_estimators=3000, criterion=entropy, max_depth=2 ...............\n",
      "[CV]  n_estimators=3000, criterion=entropy, max_depth=2, score=0.612500 -   7.5s\n",
      "[CV] n_estimators=1000, criterion=entropy, max_depth=3 ...............\n",
      "[CV]  n_estimators=1000, criterion=entropy, max_depth=3, score=0.611765 -   2.6s\n",
      "[CV] n_estimators=1000, criterion=entropy, max_depth=3 ...............\n",
      "[CV]  n_estimators=1000, criterion=entropy, max_depth=3, score=0.621951 -   2.6s\n",
      "[CV] n_estimators=1000, criterion=entropy, max_depth=3 ...............\n",
      "[CV]  n_estimators=1000, criterion=entropy, max_depth=3, score=0.675000 -   2.6s\n",
      "[CV] n_estimators=2000, criterion=entropy, max_depth=3 ...............\n",
      "[CV]  n_estimators=2000, criterion=entropy, max_depth=3, score=0.588235 -   5.2s\n",
      "[CV] n_estimators=2000, criterion=entropy, max_depth=3 ...............\n",
      "[CV]  n_estimators=2000, criterion=entropy, max_depth=3, score=0.609756 -   5.2s\n",
      "[CV] n_estimators=2000, criterion=entropy, max_depth=3 ...............\n",
      "[CV]  n_estimators=2000, criterion=entropy, max_depth=3, score=0.700000 -   5.2s\n",
      "[CV] n_estimators=3000, criterion=entropy, max_depth=3 ...............\n",
      "[CV]  n_estimators=3000, criterion=entropy, max_depth=3, score=0.588235 -   8.0s\n",
      "[CV] n_estimators=3000, criterion=entropy, max_depth=3 ...............\n",
      "[CV]  n_estimators=3000, criterion=entropy, max_depth=3, score=0.634146 -   7.9s\n",
      "[CV] n_estimators=3000, criterion=entropy, max_depth=3 ...............\n",
      "[CV]  n_estimators=3000, criterion=entropy, max_depth=3, score=0.712500 -   7.9s\n",
      "[CV] n_estimators=1000, criterion=entropy, max_depth=4 ...............\n",
      "[CV]  n_estimators=1000, criterion=entropy, max_depth=4, score=0.647059 -   2.7s\n",
      "[CV] n_estimators=1000, criterion=entropy, max_depth=4 ...............\n",
      "[CV]  n_estimators=1000, criterion=entropy, max_depth=4, score=0.695122 -   2.7s\n",
      "[CV] n_estimators=1000, criterion=entropy, max_depth=4 ...............\n",
      "[CV]  n_estimators=1000, criterion=entropy, max_depth=4, score=0.700000 -   2.7s\n",
      "[CV] n_estimators=2000, criterion=entropy, max_depth=4 ...............\n",
      "[CV]  n_estimators=2000, criterion=entropy, max_depth=4, score=0.658824 -   5.5s\n",
      "[CV] n_estimators=2000, criterion=entropy, max_depth=4 ...............\n",
      "[CV]  n_estimators=2000, criterion=entropy, max_depth=4, score=0.695122 -   5.5s\n",
      "[CV] n_estimators=2000, criterion=entropy, max_depth=4 ...............\n",
      "[CV]  n_estimators=2000, criterion=entropy, max_depth=4, score=0.700000 -   5.7s\n",
      "[CV] n_estimators=3000, criterion=entropy, max_depth=4 ...............\n",
      "[CV]  n_estimators=3000, criterion=entropy, max_depth=4, score=0.635294 -   8.4s\n",
      "[CV] n_estimators=3000, criterion=entropy, max_depth=4 ...............\n",
      "[CV]  n_estimators=3000, criterion=entropy, max_depth=4, score=0.695122 -   8.4s\n",
      "[CV] n_estimators=3000, criterion=entropy, max_depth=4 ...............\n",
      "[CV]  n_estimators=3000, criterion=entropy, max_depth=4, score=0.687500 -   8.4s\n",
      "[CV] n_estimators=1000, criterion=entropy, max_depth=None ............\n",
      "[CV]  n_estimators=1000, criterion=entropy, max_depth=None, score=0.635294 -   3.1s\n",
      "[CV] n_estimators=1000, criterion=entropy, max_depth=None ............\n",
      "[CV]  n_estimators=1000, criterion=entropy, max_depth=None, score=0.609756 -   3.0s\n",
      "[CV] n_estimators=1000, criterion=entropy, max_depth=None ............\n",
      "[CV]  n_estimators=1000, criterion=entropy, max_depth=None, score=0.662500 -   3.0s\n",
      "[CV] n_estimators=2000, criterion=entropy, max_depth=None ............\n",
      "[CV]  n_estimators=2000, criterion=entropy, max_depth=None, score=0.647059 -   6.2s\n",
      "[CV] n_estimators=2000, criterion=entropy, max_depth=None ............\n",
      "[CV]  n_estimators=2000, criterion=entropy, max_depth=None, score=0.621951 -   6.1s\n",
      "[CV] n_estimators=2000, criterion=entropy, max_depth=None ............\n",
      "[CV]  n_estimators=2000, criterion=entropy, max_depth=None, score=0.662500 -   6.2s\n",
      "[CV] n_estimators=3000, criterion=entropy, max_depth=None ............\n",
      "[CV]  n_estimators=3000, criterion=entropy, max_depth=None, score=0.647059 -   9.2s\n",
      "[CV] n_estimators=3000, criterion=entropy, max_depth=None ............\n",
      "[CV]  n_estimators=3000, criterion=entropy, max_depth=None, score=0.621951 -   9.3s\n",
      "[CV] n_estimators=3000, criterion=entropy, max_depth=None ............\n",
      "[CV]  n_estimators=3000, criterion=entropy, max_depth=None, score=0.650000 -   9.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 jobs       | elapsed:  5.8min\n",
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best score: 0.684\n",
      "Best parameters set:\n",
      "{'warm_start': False, 'oob_score': False, 'n_jobs': 1, 'verbose': 0, 'max_leaf_nodes': None, 'bootstrap': True, 'min_samples_leaf': 1, 'n_estimators': 2000, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'criterion': 'gini', 'random_state': None, 'max_features': 'auto', 'max_depth': 4, 'class_weight': None}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators' : [1000, 2000, 3000],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [1,2,3,4, None]\n",
    "}\n",
    "\n",
    "est = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(est, params, verbose=5).fit(x_train, y_train)\n",
    "\n",
    "print 'Best score: %0.3f' % grid_search.best_score_\n",
    "print 'Best parameters set:'\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "\n",
    "print best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.642389459077\n",
      "0.0548238242228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Height_scaled', 0.35439390620415961),\n",
       " ('Weight_scaled', 0.34646337512205938),\n",
       " ('Avg_Pts_scaled', 0.1850060129023165),\n",
       " ('Avg_Tries_scaled', 0.11413670577146463)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfc = RandomForestClassifier(n_estimators=2000, criterion='gini', max_depth=4)\n",
    "scores = cross_val_score(norm_rfc, scale_X, Y, cv=5)\n",
    "\n",
    "print scores.mean()\n",
    "print scores.std()\n",
    "\n",
    "best_rfc.fit(scale_X,Y)\n",
    "sorted(zip(scale_df.columns, best_rfc.feature_importances_),key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1adb2eb8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD7CAYAAABZjGkWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRNhAQoQNJETYQEKEDSRE2EBChA0k9H8RuzhuCGwh/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f9bef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_rfc.fit(x_train, y_train)\n",
    "best_rfc_pred = best_rfc.predict(x_test)\n",
    "best_rfc_cm = confusion_matrix(y_test, best_rfc_pred)\n",
    "plt.imshow(best_rfc_cm, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  2,  0,  0,  0,  2,  1,  0,  0],\n",
       "       [ 2,  2,  1,  0,  0,  0,  0,  1,  1],\n",
       "       [ 0,  0,  4,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  5,  0,  0,  0,  0,  0,  1,  1],\n",
       "       [ 2,  1,  0,  0,  2,  0,  4,  0,  1],\n",
       "       [ 1,  0,  0,  0,  0,  9,  0,  0,  0],\n",
       "       [ 3,  0,  0,  0,  0,  0,  8,  0,  0],\n",
       "       [ 0,  2,  1,  0,  0,  0,  0,  4,  0],\n",
       "       [ 1,  4,  0,  0,  0,  1,  0,  0,  5]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfc_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Back Row       0.55      0.69      0.61        16\n",
      "     Centre       0.12      0.29      0.17         7\n",
      "   Fly Half       0.67      1.00      0.80         4\n",
      "  Full Back       0.00      0.00      0.00         7\n",
      "     Hooker       1.00      0.20      0.33        10\n",
      "       Lock       0.75      0.90      0.82        10\n",
      "       Prop       0.62      0.73      0.67        11\n",
      " Scrum Half       0.67      0.57      0.62         7\n",
      "       Wing       0.62      0.45      0.53        11\n",
      "\n",
      "avg / total       0.58      0.54      0.52        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, best_rfc_pred, target_names=positions);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much of a change, indeed the gridsearched model has a lower recall and f1-score then the basic model (though all that has changed is max depth). Lets see how it applies to predicted the two test players. test_rows currently contains all the columns so first we create a dataframe that only has the scaled columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scale_values = [test_rows['Height_scaled'], test_rows['Weight_scaled'],  test_rows['Avg_Pts_scaled'], test_rows['Avg_Tries_scaled']]\n",
    "\n",
    "test_rows_df = pd.concat(scale_values, axis = 1)\n",
    "\n",
    "test_rows_X = test_rows_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifer - No GridSearch\n",
      "Name\t\t Position\t Prediction\t Probability\n",
      "Brian O'Driscoll Centre\t\t Wing\t\t 0.80\n",
      "Ronan O'Gara\t Fly-Half\t Fly Half\t 0.84\n",
      "\n",
      "Random Forest Classifer - Using BestGrid Search Parameters\n",
      "Name\t\t Position\t Prediction\t Probability\n",
      "Brian O'Driscoll Centre\t\t Wing\t\t 0.53\n",
      "Ronan O'Gara\t Fly-Half\t Fly Half\t 0.65\n"
     ]
    }
   ],
   "source": [
    "scale_rfc.fit(scale_X, Y)\n",
    "test_pred = scale_rfc.predict(test_rows_X)\n",
    "test_proba = scale_rfc.predict_proba(test_rows_X)\n",
    "print \"Random Forest Classifer - No GridSearch\"\n",
    "print \"Name\\t\\t Position\\t Prediction\\t Probability\"\n",
    "print \"Brian O'Driscoll Centre\\t\\t %s\\t\\t %0.2f\\nRonan O'Gara\\t Fly-Half\\t %s\\t %0.2f\" % (positions[int(test_pred[0])], max(test_proba[0]), positions[int(test_pred[1])], max(test_proba[1]))\n",
    "\n",
    "print \"\"\n",
    "best_rfc.fit(scale_X, Y)\n",
    "test_pred2 = best_rfc.predict(test_rows_X)\n",
    "test_proba2 = best_rfc.predict_proba(test_rows_X)\n",
    "print \"Random Forest Classifer - Using BestGrid Search Parameters\"\n",
    "print \"Name\\t\\t Position\\t Prediction\\t Probability\"\n",
    "print \"Brian O'Driscoll Centre\\t\\t %s\\t\\t %0.2f\\nRonan O'Gara\\t Fly-Half\\t %s\\t %0.2f\" % (positions[int(test_pred2[0])], max(test_proba2[0]), positions[int(test_pred2[1])], max(test_proba2[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both times our models predict Brian O'Driscoll to be a Wing but they both get O'Gara correct. What is different though is the probability or certinty each model predicts for each position. The first model is 80% certin O'Driscoll is a Wing where as the second is 53%. There is also a big drop in certinty for O'Gara. Below is the probability each model assigned each player for each position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for Brian O'Driscoll\n",
      "No GridSearch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Wing', 0.79749999999999999),\n",
       " ('Centre', 0.062),\n",
       " ('Scrum Half', 0.061499999999999999),\n",
       " ('Fly Half', 0.032500000000000001),\n",
       " ('Full Back', 0.031),\n",
       " ('Hooker', 0.0089999999999999993),\n",
       " ('Back Row', 0.0064999999999999997),\n",
       " ('Lock', 0.0),\n",
       " ('Prop', 0.0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Probabilities for Brian O'Driscoll\"\n",
    "print \"No GridSearch\"\n",
    "sorted(zip(positions,test_proba[0]),key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearched\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Wing', 0.53435193401178072),\n",
       " ('Centre', 0.1822288294254821),\n",
       " ('Scrum Half', 0.099770383938151491),\n",
       " ('Fly Half', 0.072088939819069539),\n",
       " ('Full Back', 0.056671908659138744),\n",
       " ('Back Row', 0.028130221683530403),\n",
       " ('Hooker', 0.025340993720654362),\n",
       " ('Prop', 0.0013582177982544544),\n",
       " ('Lock', 5.8570943939277372e-05)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"GridSearched\"\n",
    "sorted(zip(positions,test_proba2[0]),key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for Ronan O'Gara\n",
      "No GridSearch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Fly Half', 0.84099999999999997),\n",
       " ('Scrum Half', 0.1115),\n",
       " ('Centre', 0.033500000000000002),\n",
       " ('Full Back', 0.012999999999999999),\n",
       " ('Wing', 0.001),\n",
       " ('Back Row', 0.0),\n",
       " ('Hooker', 0.0),\n",
       " ('Lock', 0.0),\n",
       " ('Prop', 0.0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Probabilities for Ronan O'Gara\"\n",
    "print \"No GridSearch\"\n",
    "\n",
    "sorted(zip(positions,test_proba[1]),key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearched\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Fly Half', 0.65316154655925784),\n",
       " ('Scrum Half', 0.18912360333195405),\n",
       " ('Centre', 0.074358679525168517),\n",
       " ('Full Back', 0.03963133461732455),\n",
       " ('Wing', 0.036368863088349399),\n",
       " ('Hooker', 0.0035532250908393592),\n",
       " ('Back Row', 0.0027619279747177323),\n",
       " ('Prop', 0.0010314740179969558),\n",
       " ('Lock', 9.3457943925233634e-06)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"GridSearched\"\n",
    "sorted(zip(positions,test_proba2[1]),key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first, non-gridsearched model makes very bold statements, assigning very high probabilities to a single value and declaring it to be impossible for the player to play in half the positions. However the model is not alone very confident but very wrong in some cases. \n",
    "\n",
    "The second model is less sure of itself. In the case of O'Driscoll it would be nice if the lack of confidence in him being a wing bought up the probability of him being a centre but it gets spread out amoung a number of positions deemed impossible by the first model. A combination of these models may yeild better results then any one single model.\n",
    "\n",
    "While the model is very inaccurate in some areas it has very limited data in both number of variables and observations. The addition of weaker rugby nations has a negative impact on the accuracy score but this could maybe be countered by normalizing and scaling each nation before creating a combined dataframe. \n",
    "\n",
    "Just two variables, height and weight, contribute to 60% of the models prediction. The inclusion of other physical variables, such as weight lifting pbs or best sprint times might also help improve the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
